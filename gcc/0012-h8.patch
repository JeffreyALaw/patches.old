diff --git a/gcc/config/h8300/addsub.md b/gcc/config/h8300/addsub.md
index b1eb0d20188..b67b1026346 100644
--- a/gcc/config/h8300/addsub.md
+++ b/gcc/config/h8300/addsub.md
@@ -239,3 +239,203 @@
   "reload_completed"
   "xor.w\\t#32768,%e0"
   [(set_attr "length" "4")])
+
+
+;; Basic overflow checking support.  These are nowhere near complete, but
+;; are sufficient to speed up the testsuite enough that the overflow
+;; tests are much less likely to timeout.
+(define_expand "addv<mode>4"
+  [(parallel
+    [(set (reg:CCV CC_REG)
+	  (ne:CCV
+	    (plus:<OVF>
+	      (sign_extend:<OVF> (match_operand:QHSI 1 "register_operand" ""))
+	      (sign_extend:<OVF> (match_operand:QHSI 2 "register_operand" "")))
+	    (sign_extend:<OVF> (plus:QHSI (match_dup 1) (match_dup 2)))))
+     (set (match_operand:QHSI 0 "register_operand" "")
+	  (plus:QHSI (match_dup 1) (match_dup 2)))])
+   (set (pc) (if_then_else
+	       (ne (reg:CCV CC_REG) (const_int 0))
+	       (label_ref (match_operand 3))
+	       (pc)))])
+
+(define_expand "uaddv<mode>4"
+  [(parallel
+    [(set (reg:CCC CC_REG)
+	  (ne:CCC
+	    (plus:<OVF>
+	      (zero_extend:<OVF> (match_operand:QHSI 1 "register_operand" ""))
+	      (zero_extend:<OVF> (match_operand:QHSI 2 "register_operand" "")))
+	    (zero_extend:<OVF> (plus:QHSI (match_dup 1) (match_dup 2)))))
+     (set (match_operand:QHSI 0 "register_operand" "")
+	  (plus:QHSI (match_dup 1) (match_dup 2)))])
+   (set (pc) (if_then_else
+	       (ne (reg:CCC CC_REG) (const_int 0))
+	       (label_ref (match_operand 3))
+	       (pc)))])
+
+(define_expand "subv<mode>4"
+  [(parallel
+    [(set (reg:CCV CC_REG)
+	  (ne:CCV
+	    (minus:<OVF>
+	      (sign_extend:<OVF> (match_operand:QHSI 1 "register_operand" ""))
+	      (sign_extend:<OVF> (match_operand:QHSI 2 "register_operand" "")))
+	    (sign_extend:<OVF> (plus:QHSI (match_dup 1) (match_dup 2)))))
+     (set (match_operand:QHSI 0 "register_operand" "")
+	  (minus:QHSI (match_dup 1) (match_dup 2)))])
+   (set (pc) (if_then_else
+	       (ne (reg:CCV CC_REG) (const_int 0))
+	       (label_ref (match_operand 3))
+	       (pc)))])
+
+(define_expand "usubv<mode>4"
+  [(parallel
+    [(set (reg:CCC CC_REG)
+	  (ne:CCC
+	    (minus:<OVF>
+	      (zero_extend:<OVF> (match_operand:QHSI 1 "register_operand" ""))
+	      (zero_extend:<OVF> (match_operand:QHSI 2 "register_operand" "")))
+	    (zero_extend:<OVF> (plus:QHSI (match_dup 1) (match_dup 2)))))
+     (set (match_operand:QHSI 0 "register_operand" "")
+	  (minus:QHSI (match_dup 1) (match_dup 2)))])
+   (set (pc) (if_then_else
+	       (ne (reg:CCC CC_REG) (const_int 0))
+	       (label_ref (match_operand 3))
+	       (pc)))])
+
+(define_insn "*addv<mode>4"
+  [(set (reg:CCV CC_REG)
+	(ne:CCV (plus:<OVF>
+		   (sign_extend:<OVF>
+		     (match_operand:QHSI 1 "register_operand" "%0"))
+		   (sign_extend:<OVF>
+		     (match_operand:QHSI 2 "register_operand" "r")))
+		 (sign_extend:<OVF> (plus:QHSI (match_dup 1) (match_dup 2)))))
+  (set (match_operand:QHSI 0 "register_operand" "=r")
+       (plus:QHSI (match_dup 1) (match_dup 2)))]
+  ""
+{
+  if (GET_MODE (operands[0]) == QImode)
+    return "add.b %X2,%X0";
+  else if (GET_MODE (operands[0]) == HImode)
+    return "add.w %T2,%T0";
+  else if (GET_MODE (operands[0]) == SImode)
+    return "add.l %S2,%S0";
+  else
+   gcc_unreachable ();
+}
+  [(set_attr "length" "2")])
+
+(define_insn "*addv<mode>4_rev"
+  [(set (reg:CCV CC_REG)
+	(ne:CCV (plus:<OVF>
+		   (sign_extend:<OVF>
+		     (match_operand:QHSI 1 "register_operand" "%0"))
+		   (sign_extend:<OVF>
+		     (match_operand:QHSI 2 "register_operand" "r")))
+		 (sign_extend:<OVF> (plus:QHSI (match_dup 2) (match_dup 1)))))
+  (set (match_operand:QHSI 0 "register_operand" "=r")
+       (plus:QHSI (match_dup 2) (match_dup 1)))]
+  ""
+{
+  if (GET_MODE (operands[0]) == QImode)
+    return "add.b %X2,%X0";
+  else if (GET_MODE (operands[0]) == HImode)
+    return "add.w %T2,%T0";
+  else if (GET_MODE (operands[0]) == SImode)
+    return "add.l %S2,%S0";
+  else
+   gcc_unreachable ();
+}
+  [(set_attr "length" "2")])
+
+(define_insn "*uaddv<mode>4"
+  [(set (reg:CCC CC_REG)
+	(ne:CCC
+	  (plus:<OVF>
+	    (zero_extend:<OVF> (match_operand:QHSI 1 "register_operand" "%0"))
+	    (zero_extend:<OVF> (match_operand:QHSI 2 "register_operand" "r")))
+	  (zero_extend:<OVF> (plus:QHSI (match_dup 1) (match_dup 2)))))
+   (set (match_operand:QHSI 0 "register_operand" "=r")
+	(plus:QHSI (match_dup 1) (match_dup 2)))]
+  ""
+{
+  if (GET_MODE (operands[0]) == QImode)
+    return "add.b %X2,%X0";
+  else if (GET_MODE (operands[0]) == HImode)
+    return "add.w %T2,%T0";
+  else if (GET_MODE (operands[0]) == SImode)
+    return "add.l %S2,%S0";
+  else
+   gcc_unreachable ();
+}
+  [(set_attr "length" "2")])
+
+(define_insn "*uaddv<mode>4_rev"
+  [(set (reg:CCC CC_REG)
+	(ne:CCC
+	  (plus:<OVF>
+	    (zero_extend:<OVF> (match_operand:QHSI 1 "register_operand" "%0"))
+	    (zero_extend:<OVF> (match_operand:QHSI 2 "register_operand" "r")))
+	  (zero_extend:<OVF> (plus:QHSI (match_dup 2) (match_dup 1)))))
+   (set (match_operand:QHSI 0 "register_operand" "=r")
+	(plus:QHSI (match_dup 2) (match_dup 1)))]
+  ""
+{
+  if (GET_MODE (operands[0]) == QImode)
+    return "add.b %X2,%X0";
+  else if (GET_MODE (operands[0]) == HImode)
+    return "add.w %T2,%T0";
+  else if (GET_MODE (operands[0]) == SImode)
+    return "add.l %S2,%S0";
+  else
+   gcc_unreachable ();
+}
+  [(set_attr "length" "2")])
+
+(define_insn "*subvqi4"
+  [(set (reg:CCV CC_REG)
+	(ne:CCV (minus:<OVF>
+		   (sign_extend:<OVF>
+		     (match_operand:QHSI 1 "register_operand" "0"))
+		   (sign_extend:<OVF>
+		     (match_operand:QHSI 2 "register_operand" "r")))
+		 (sign_extend:<OVF> (plus:QHSI (match_dup 1) (match_dup 2)))))
+  (set (match_operand:QHSI 0 "register_operand" "=r")
+       (minus:QHSI (match_dup 1) (match_dup 2)))]
+  ""
+{
+  if (GET_MODE (operands[0]) == QImode)
+    return "sub.b %X2,%X0";
+  else if (GET_MODE (operands[0]) == HImode)
+    return "sub.w %T2,%T0";
+  else if (GET_MODE (operands[0]) == SImode)
+    return "sub.l %S2,%S0";
+  else
+   gcc_unreachable ();
+}
+  [(set_attr "length" "2")])
+
+(define_insn "*usubvqi4"
+  [(set (reg:CCC CC_REG)
+	(ne:CCC (minus:<OVF>
+		   (zero_extend:<OVF>
+		     (match_operand:QHSI 1 "register_operand" "0"))
+		   (zero_extend:<OVF>
+		     (match_operand:QHSI 2 "register_operand" "r")))
+		 (zero_extend:<OVF> (plus:QHSI (match_dup 1) (match_dup 2)))))
+  (set (match_operand:QHSI 0 "register_operand" "=r")
+       (minus:QHSI (match_dup 1) (match_dup 2)))]
+  ""
+{
+  if (GET_MODE (operands[0]) == QImode)
+    return "sub.b %X2,%X0";
+  else if (GET_MODE (operands[0]) == HImode)
+    return "sub.w %T2,%T0";
+  else if (GET_MODE (operands[0]) == SImode)
+    return "sub.l %S2,%S0";
+  else
+   gcc_unreachable ();
+}
+  [(set_attr "length" "2")])
diff --git a/gcc/config/h8300/bitfield.md b/gcc/config/h8300/bitfield.md
index 82cb161d126..0d28c750a6a 100644
--- a/gcc/config/h8300/bitfield.md
+++ b/gcc/config/h8300/bitfield.md
@@ -338,17 +338,6 @@
 }
   [(set_attr "length_table" "bitfield")])
 
-;;(define_expand "cstore<mode>4"
-;;  [(use (match_operator 1 "eqne_operator"
-;;         [(match_operand:QHSI 2 "h8300_dst_operand" "")
-;;          (match_operand:QHSI 3 "h8300_src_operand" "")]))
-;;   (clobber (match_operand:QHSI 0 "register_operand"))]
-;;  "TARGET_H8300SX"
-;;  {
-;;    h8300_expand_store (operands);
-;;    DONE;
-;;  })
-
 ;;(define_insn "*bstzhireg"
 ;;  [(set (match_operand:HI 0 "register_operand" "=r")
 ;;	(match_operator:HI 1 "eqne_operator" [(cc0) (const_int 0)]))]
diff --git a/gcc/config/h8300/h8300-protos.h b/gcc/config/h8300/h8300-protos.h
index 744337d6667..90fdb52d3da 100644
--- a/gcc/config/h8300/h8300-protos.h
+++ b/gcc/config/h8300/h8300-protos.h
@@ -45,7 +45,6 @@ extern int compute_a_shift_cc (rtx *, rtx_code);
 #ifdef HAVE_ATTR_cc
 extern enum attr_cc compute_plussi_cc (rtx *);
 #endif
-extern void h8300_expand_branch (rtx[]);
 extern void h8300_expand_store (rtx[]);
 extern bool expand_a_shift (machine_mode, enum rtx_code, rtx[]);
 extern int h8300_shift_needs_scratch_p (int, machine_mode, rtx_code);
diff --git a/gcc/config/h8300/h8300.c b/gcc/config/h8300/h8300.c
index 8ccacecba79..c56cc20d771 100644
--- a/gcc/config/h8300/h8300.c
+++ b/gcc/config/h8300/h8300.c
@@ -3255,30 +3255,8 @@ compute_logical_op_length (machine_mode mode, rtx_code code, rtx *operands, rtx_
   return length;
 }
 
-
 #if 0
-/* Expand a conditional branch.  */
-
-void
-h8300_expand_branch (rtx operands[])
-{
-  enum rtx_code code = GET_CODE (operands[0]);
-  rtx op0 = operands[1];
-  rtx op1 = operands[2];
-  rtx label = operands[3];
-  rtx tmp;
-
-  tmp = gen_rtx_COMPARE (VOIDmode, op0, op1);
-  emit_insn (gen_rtx_SET (cc0_rtx, tmp));
-
-  tmp = gen_rtx_fmt_ee (code, VOIDmode, cc0_rtx, const0_rtx);
-  tmp = gen_rtx_IF_THEN_ELSE (VOIDmode, tmp,
-			      gen_rtx_LABEL_REF (VOIDmode, label),
-			      pc_rtx);
-  emit_jump_insn (gen_rtx_SET (pc_rtx, tmp));
-}
-
-
+
 /* Expand a conditional store.  */
 
 void
@@ -3290,10 +3268,7 @@ h8300_expand_store (rtx operands[])
   rtx op1 = operands[3];
   rtx tmp;
 
-  tmp = gen_rtx_COMPARE (VOIDmode, op0, op1);
-  emit_insn (gen_rtx_SET (cc0_rtx, tmp));
-
-  tmp = gen_rtx_fmt_ee (code, GET_MODE (dest), cc0_rtx, const0_rtx);
+  tmp = gen_rtx_fmt_ee (code, GET_MODE (dest), op0, op1);
   emit_insn (gen_rtx_SET (dest, tmp));
 }
 #endif
diff --git a/gcc/config/h8300/h8300.md b/gcc/config/h8300/h8300.md
index 7f49e4284f2..d11700a3aad 100644
--- a/gcc/config/h8300/h8300.md
+++ b/gcc/config/h8300/h8300.md
@@ -68,6 +68,10 @@
    (FP_REG	11)
    (CC_REG	12)])
 
+;; Map from an integer mode to the next wider integer mode
+;; Useful for constructing the overflow patterns
+(define_mode_attr OVF [(QI "HI") (HI "SI") (SI "DI")])
+
 ;; ----------------------------------------------------------------------
 ;; ATTRIBUTES
 ;; ----------------------------------------------------------------------
diff --git a/gcc/config/h8300/jumpcall.md b/gcc/config/h8300/jumpcall.md
index 3e59fee58bd..17aadabe998 100644
--- a/gcc/config/h8300/jumpcall.md
+++ b/gcc/config/h8300/jumpcall.md
@@ -67,6 +67,76 @@
 }
  [(set_attr "type" "branch")])
 
+;; This is the bare minimum to support the builtin overflow
+;; checking patterns.  It could possibly be merged into the
+;; other branch patterns given time and interest.
+(define_insn "*branch_1_v_set"
+  [(set (pc)
+	(if_then_else (ne (reg:CCV CC_REG) (const_int 0))
+		      (label_ref (match_operand 0 "" ""))
+		      (pc)))]
+  ""
+{
+  if (get_attr_length (insn) == 2)
+    return "bvs	%l0";
+  else if (get_attr_length (insn) == 4)
+    return "bvs	%l0:16";
+  else
+    return "bvc	.Lh8BR%=\;jmp	@%l0\\n.Lh8BR%=:";
+}
+ [(set_attr "type" "branch")])
+
+;; This is the bare minimum to support the builtin overflow
+;; checking patterns.  It could possibly be merged into the
+;; other branch patterns given time and interest.
+(define_insn "*branch_1_v_clear"
+  [(set (pc)
+	(if_then_else (eq (reg:CCV CC_REG) (const_int 0))
+		      (label_ref (match_operand 0 "" ""))
+		      (pc)))]
+  ""
+{
+  if (get_attr_length (insn) == 2)
+    return "bvc	%l0";
+  else if (get_attr_length (insn) == 4)
+    return "bvc	%l0:16";
+  else
+    return "bvs	.Lh8BR%=\;jmp	@%l0\\n.Lh8BR%=:";
+}
+ [(set_attr "type" "branch")])
+
+(define_insn "*branch_1_c_set"
+  [(set (pc)
+	(if_then_else (ne (reg:CCC CC_REG) (const_int 0))
+		      (label_ref (match_operand 0 "" ""))
+		      (pc)))]
+  ""
+{
+  if (get_attr_length (insn) == 2)
+    return "bcs	%l0";
+  else if (get_attr_length (insn) == 4)
+    return "bcs	%l0:16";
+  else
+    return "bcc	.Lh8BR%=\;jmp	@%l0\\n.Lh8BR%=:";
+}
+ [(set_attr "type" "branch")])
+
+(define_insn "*branch_1_c_clear"
+  [(set (pc)
+	(if_then_else (eq (reg:CCC CC_REG) (const_int 0))
+		      (label_ref (match_operand 0 "" ""))
+		      (pc)))]
+  ""
+{
+  if (get_attr_length (insn) == 2)
+    return "bcc	%l0";
+  else if (get_attr_length (insn) == 4)
+    return "bcc	%l0:16";
+  else
+    return "bcs	.Lh8BR%=\;jmp	@%l0\\n.Lh8BR%=:";
+}
+ [(set_attr "type" "branch")])
+
 
 (define_insn "*branch_1_false"
   [(set (pc)
diff --git a/gcc/config/h8300/testcompare.md b/gcc/config/h8300/testcompare.md
index 29190532e49..54d3bc50b38 100644
--- a/gcc/config/h8300/testcompare.md
+++ b/gcc/config/h8300/testcompare.md
@@ -70,6 +70,22 @@
   "mov.w	%e0,%e0"
   [(set_attr "length" "2")])
 
+(define_insn "*cmp<mode>_c"
+  [(set (reg:CCC CC_REG)
+	(ltu (match_operand:QHSI 0 "h8300_dst_operand" "rQ")
+	     (match_operand:QHSI 1 "h8300_src_operand" "rQi")))]
+  "reload_completed"
+  {
+    if (<MODE>mode == QImode)
+      return "cmp.b	%X1,%X0";
+    else if (<MODE>mode == HImode)
+      return "cmp.w	%T1,%T0";
+    else if (<MODE>mode == SImode)
+      return "cmp.l	%S1,%S0";
+    gcc_unreachable ();
+  }
+  [(set_attr "length_table" "add")])
+
 (define_insn "*cmpqi"
   [(set (reg:CC CC_REG)
 	(compare (match_operand:QI 0 "h8300_dst_operand" "rQ")
@@ -144,3 +160,80 @@
   [(parallel [(set (reg:CCZN CC_REG) (compare:CCZN (match_dup 1) (const_int 0)))
 	      (set (match_dup 0) (match_dup 1))])])
 
+;; This exists solely to convince ifcvt to try some store-flag sequences.
+;;
+;; Essentially we don't want to expose a general store-flag capability.
+;; The only generally useful/profitable case is when we want to test the
+;; C bit.  In that case we can use addx, subx, bst, or bist to get the bit
+;; into a GPR.
+;;
+;; Others could be handled with stc, shifts and masking, but it likely isn't
+;; profitable.
+;;
+(define_expand "cstore<mode>4"
+  [(use (match_operator 1 "eqne_operator"
+         [(match_operand:QHSI 2 "h8300_dst_operand" "")
+          (match_operand:QHSI 3 "h8300_src_operand" "")]))
+   (clobber (match_operand:QHSI 0 "register_operand"))]
+  ""
+  {
+    FAIL;
+  })
+
+;; We can use the C bit directly
+(define_insn "*cstore<mode>"
+  [(set (match_operand:QHSI 0 "register_operand" "=r")
+	(ne:QHSI (reg:CCC CC_REG) (const_int 0)))]
+  ""
+  {
+    if (<MODE>mode == QImode)
+      return "xor.b\t%X0,%X0\;bst\t#0,%X0";
+    else if (<MODE>mode == HImode)
+      return "xor.w\t%T0,%T0\;bst\t#0,%s0";
+    else if (<MODE>mode == SImode)
+      return "xor.l\t%S0,%S0\;bst\t#0,%w0";
+    gcc_unreachable ();
+  }
+  [(set (attr "length") (symbol_ref "<MODE>mode == SImode ? 6 : 4"))])
+
+;; We need the inverted C bit
+(define_insn "*inverted_cstore<mode>"
+  [(set (match_operand:QHSI 0 "register_operand" "=r")
+	(eq:QHSI (reg:CCC CC_REG) (const_int 0)))]
+  ""
+  {
+    if (<MODE>mode == QImode)
+      return "xor.b\t%X0,%X0\;bist\t#0,%X0";
+    else if (<MODE>mode == HImode)
+      return "xor.w\t%T0,%T0\;bist\t#0,%s0";
+    else if (<MODE>mode == SImode)
+      return "xor.l\t%S0,%S0\;bist\t#0,%w0";
+    gcc_unreachable ();
+  }
+  [(set (attr "length") (symbol_ref "<MODE>mode == SImode ? 6 : 2"))])
+
+;; Recognize this scc and generate code we can match
+(define_insn_and_split "*cstore<mode>"
+  [(set (match_operand:QHSI 0 "register_operand" "")
+	(ltu:QHSI (match_operand:QHSI 1 "register_operand" "")
+		  (match_operand:QHSI 2 "register_operand" "")))]
+  ""
+  "#"
+  "&& reload_completed"
+  [(set (reg:CCC CC_REG)
+	(ltu:CCC (match_dup 1) (match_dup 2)))
+   (set (match_dup 0)
+	(ne:QHSI (reg:CCC CC_REG) (const_int 0)))])
+
+(define_insn_and_split "*cstore<mode>"
+  [(set (match_operand:QHSI 0 "register_operand" "")
+	(geu:QHSI (match_operand:QHSI 1 "register_operand" "")
+		  (match_operand:QHSI 2 "register_operand" "")))]
+  ""
+  "#"
+  "&& reload_completed"
+  [(set (reg:CCC CC_REG)
+	(ltu:CCC (match_dup 1) (match_dup 0)))
+   (set (match_dup 0)
+	(eq:QHSI (reg:CCC CC_REG) (const_int 0)))])
+
diff --git a/gcc/ifcvt.c b/gcc/ifcvt.c
index 017944f4f79..f6c7208df57 100644
--- a/gcc/ifcvt.c
+++ b/gcc/ifcvt.c
@@ -1535,7 +1535,7 @@ noce_try_store_flag_constants (struct noce_if_info *if_info)
 	noce_emit_move_insn (if_info->x, target);
 
       seq = end_ifcvt_sequence (if_info);
-      if (!seq || !targetm.noce_conversion_profitable_p (seq, if_info))
+      if (!seq/* || !targetm.noce_conversion_profitable_p (seq, if_info)*/)
 	return FALSE;
 
       emit_insn_before_setloc (seq, if_info->jump,
